
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──
✔ broom        1.0.5     ✔ recipes      1.0.8
✔ dials        1.2.0     ✔ rsample      1.2.0
✔ dplyr        1.1.3     ✔ tibble       3.2.1
✔ ggplot2      3.4.3     ✔ tidyr        1.3.0
✔ infer        1.0.5     ✔ tune         1.1.2
✔ modeldata    1.2.0     ✔ workflows    1.1.3
✔ parsnip      1.1.1     ✔ workflowsets 1.0.1
✔ purrr        1.0.2     ✔ yardstick    1.2.0
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Search for functions across packages at https://www.tidymodels.org/find/
> library(embed) # For target encoding
> library(vroom) 

Attaching package: ‘vroom’

The following object is masked from ‘package:yardstick’:

    spec

The following object is masked from ‘package:scales’:

    col_factor

> library(parallel)
> library(ggmosaic) # For plotting
> 
> # Logistic Regression -----------------------------------------------------
> 
> # Reading in the Data
> AEAC_Train <- vroom("train.csv") #"Amazon_AEAC_Kaggle/train.csv" for local
Rows: 32769 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): ACTION, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTN...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> AEAC_Test <- vroom("test.csv") #"Amazon_AEAC_Kaggle/test.csv" for local
Rows: 58921 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): id, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTNAME,...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> AEAC_Train$ACTION = as.factor(AEAC_Train$ACTION)
> 
> AEAC_recipe <- recipe(ACTION ~., data=AEAC_Train) %>% 
+   step_mutate_at(all_numeric_predictors(), fn= factor) %>% 
+   step_other(all_nominal_predictors(), threshold = .001) %>% 
+   step_dummy(all_nominal_predictors()) #%>% 
>   #step_lencode_mixed(all_nominal_predictors(), outcome= vars(ACTION))
> # Try step_lencode_bayes() in the future
> 
> prep <- prep(AEAC_recipe)
> baked_data <- bake(prep, new_data=AEAC_Train)
> log_reg_mod <- logistic_reg() %>% #Type of model
+   set_engine("glm")
> 
> amazon_log_workflow <- workflow() %>%
+ add_recipe(AEAC_recipe) %>%
+ add_model(log_reg_mod) %>%
+ fit(data = AEAC_Train) # Fit the workflow
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 
> 
> amazon_log_predictions <- predict(amazon_log_workflow,
+                               new_data=AEAC_Test,
+                               type= "prob") #%>% # "class" which uses cutoff as .5 or "prob" (see doc)
Warning message:
In predict.lm(object, newdata, se.fit, scale = 1, type = if (type ==  :
  prediction from rank-deficient fit; attr(*, "non-estim") has doubtful cases
>   #mutate(ACTION = ifelse(.pred_1> C,1,0)) #REPLACE C WITH WHATEVER CUTOFF I WANT
> 
> ### FOR CLASS
> # log_submission <- amazon_log_predictions %>% 
> #   mutate(id = row_number()) %>% 
> #   rename(Action = .pred_class)
> 
> ### FOR PROB
> log_submission <- amazon_log_predictions %>% 
+   mutate(id = row_number()) %>% 
+   rename(Action = .pred_1) %>% 
+   select(3,2)
> 
> vroom_write(x=log_submission, file="LogRegression.csv", delim=",") #"Amazon_AEAC_Kaggle/LogRegression.csv"
> 
> 
> # Penalized Logistic Regression -------------------------------------------
> 
> # Reading in the Data
> AEAC_Train <- vroom("train.csv") #"Amazon_AEAC_Kaggle/train.csv" for local
Rows: 32769 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): ACTION, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTN...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> AEAC_Test <- vroom("test.csv") #"Amazon_AEAC_Kaggle/test.csv" for local
Rows: 58921 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): id, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTNAME,...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> AEAC_Train$ACTION = as.factor(AEAC_Train$ACTION)
> 
> AEAC_recipe <- recipe(ACTION ~., data=AEAC_Train) %>% 
+   step_mutate_at(all_numeric_predictors(), fn= factor) %>% 
+   step_other(all_nominal_predictors(), threshold = .001) %>% 
+   #  step_dummy(all_nominal_predictors()) %>% 
+   step_lencode_mixed(all_nominal_predictors(), outcome= vars(ACTION))
> # Try step_lencode_bayes() in the future
> 
> prep <- prep(AEAC_recipe)
> baked_data <- bake(prep, new_data=AEAC_Train)
> 
> pen_log_model <- logistic_reg(mixture=tune(),
+                        penalty=tune()) %>% #Type of model
+   set_engine("glmnet")
> 
> pen_log_workflow <- workflow() %>%
+   add_recipe(AEAC_recipe) %>%
+   add_model(pen_log_model)
> 
> ## Grid of values to tune over
> pen_log_tuning_grid <- grid_regular(penalty(),
+                             mixture(), # Always bewteen 0 and 1
+                             levels = 3) ## L^2 total tuning possibilities
> 
> ## Split data for CV
> folds <- vfold_cv(AEAC_Train, v = 3, repeats=1)
> 
> ## Run the CV
> CV_results <- pen_log_workflow %>%
+   tune_grid(resamples=folds,
+             grid=pen_log_tuning_grid,
+             metrics=metric_set(roc_auc)) 
→ A | warning: Model failed to converge with max|grad| = 0.174127 (tol = 0.002, component 1), Model is nearly unidentifiable: very large eigenvalue
                - Rescale variables?
There were issues with some computations   A: x1
There were issues with some computations   A: x1

> 
> ## Find Best Tuning Parameters
> pen_log_bestTune <- CV_results %>%
+   select_best("roc_auc")
> 
> ## Finalize the Workflow & fit it
> final_wf <- pen_log_workflow %>%
+   finalize_workflow(pen_log_bestTune) %>%
+   fit(data=AEAC_Train)
> 
> ## Predict
> pen_log_preds <- final_wf %>%
+   predict(new_data = AEAC_Test, type="prob") %>% 
+   mutate(id = row_number()) %>% 
+   rename(Action = .pred_1) %>% 
+   select(3,2)
> 
> vroom_write(x=pen_log_preds, file="PenLogRegression.csv", delim=",") #"Amazon_AEAC_Kaggle/PenLogRegression.csv"
> 
> 
> 
> 
> proc.time()
    user   system  elapsed 
3491.598   50.107  477.465 
